{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate maps modeled in Pytorch Apple M1 (Metal) GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.iterated_map_utils as map_utils\n",
    "import utils.ode_utils as ode_utils\n",
    "import utils.torch_utils as torch_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorentz attractor\n",
    "\n",
    "In 1963, Edward Lorenz developed a simple mathematical model of the way air moves around in the atmosphere.\n",
    "His model was a system of three ordinary differential equations that demonstrates deterministic chaos at certain parameter values and initial conditions. The Lorenz attractor is the system's strange attractor that resembles a butterfly when visualized.\n",
    "\n",
    "The Lorenz system is nonlinear, three-dimensional, and deterministic. \n",
    "\n",
    "The Lorenz attractor is a set of chaotic solutions of the Lorenz system and is possibly the most famous depiction of a system that exibits chaotic behavior. Very slight changes to the initial conditions of the system lead to wildly different solutions. The system itself describes the movement of a point in a three-dimensional space over time using three ordinary differential equations that represent the movement of this point (x, y, z). In these equations, t represents time and sigma, rho, and beta are constant system parameters.\n",
    "\n",
    "$$ \\frac{dx}{dt} = \\sigma (y - x) $$\n",
    "\n",
    "$$ \\frac{dy}{dt} = x (\\rho - z) - y $$\n",
    "\n",
    "$$ \\frac{dz}{dt} = x y - \\beta z $$\n",
    "\n",
    "For his famous depiction of chaos, Lorenz used the values sigma = 10, beta = 8/3 and rho = 28. With these parameter values, the system exhibits deterministic chaos. It has a strange attractor with a fractal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# parameters P and variable vector V\n",
    "P = {'sigma': 10, 'beta': 8/3, 'rho': 28, 'dt': 0.01, 'n': 4000}\n",
    "V = [1.5, 0.6, 0.7]\n",
    "# trajectory T\n",
    "T = ode_utils.iterate(ode_utils.lorentz_ode, V, **P)\n",
    "# extract the individual arrays of x, y, and z values from the array of arrays\n",
    "x, y, z = tuple(T.T)\n",
    "\n",
    "# plot the lorenz attractor in three-dimensional phase space\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(x, y, z, color='g', alpha=0.7, linewidth=0.6)\n",
    "ax.set_title('Lorenz attractor phase diagram')\n",
    "# fig.savefig('{}/lorenz-attractor-3d.png'.format(save_folder), dpi=180, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class RecurrenceModel(nn.Module):\n",
    "\n",
    "    def name(self):\n",
    "        return self._get_name()\n",
    "\n",
    "    def __init__(self, hidden_units_list: list, activation_function='relu'):\n",
    "        super(RecurrenceModel, self).__init__()\n",
    "        \n",
    "        if hidden_units_list[0]!=hidden_units_list[-1]:\n",
    "            raise ValueError(f'number of input ({hidden_units_list[0]}) and output features ({hidden_units_list[-1]}) must be the same for Recurrence model {hidden_unit_list}')\n",
    "\n",
    "        self.num_layers = len(hidden_units_list)-1\n",
    "        self.activation_func = getattr(F, activation_function)\n",
    "\n",
    "        print(f'using {activation_function} activation function')\n",
    "\n",
    "        for layer_num, in_features, out_features in zip(range(self.num_layers), hidden_units_list, hidden_units_list[1:]):\n",
    "            layer = nn.Linear(in_features, out_features, bias=True)\n",
    "            setattr(self, f'fc{layer_num}', layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer_num in range (self.num_layers):\n",
    "            layer = getattr(self, f'fc{layer_num}')\n",
    "            \n",
    "            if layer_num < self.num_layers -1:\n",
    "                x = self.activation_func(layer(x))\n",
    "            else:\n",
    "                #last layer has no activation function    \n",
    "                x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train(config, device):\n",
    "    start = time.time()\n",
    "    torch_utils.reset_seed(config.seed)\n",
    "\n",
    "    # create random distributed train dataset\n",
    "    mu, sigma = 0, 30 # mean and standard deviation\n",
    "    x = np.random.normal(mu, sigma, config.num_samples)\n",
    "    y = np.random.normal(mu, sigma, config.num_samples)\n",
    "    mu, sigma = 25, 25 # mean and standard deviation\n",
    "    z = np.random.normal(mu, sigma, config.num_samples)\n",
    "\n",
    "    X_train = np.vstack((x,y,z)).T.reshape(-1,3)\n",
    "    # shuffle\n",
    "    # np.take(X_train, np.random.rand(X_train.shape[0]).argsort(), axis=0, out=X_train)\n",
    "\n",
    "    # get the target values Y\n",
    "    Y_train = ode_utils.rk4(ode_utils.lorentz_ode, X_train, t=1.0, **config.parameters)\n",
    "\n",
    "    # put X and Y in dataset, suited for Apple M1 GPU (Mps)\n",
    "    train_dataset = torch_utils.MpsDataset(X_train, Y_train, device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # init model\n",
    "    model = RecurrenceModel(config.hidden_units_list, config.activation_function)\n",
    "    model.to(config.device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    if hasattr(config, 'weight_decay'):\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    train_loss=[]\n",
    "    test_loss=[]\n",
    "\n",
    "    num_train_examples = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        with tqdm(train_loader, unit=\" batch\") as tepoch:\n",
    "            for step, (X, Y) in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "                \n",
    "                X, Y = X.to(device=config.device), Y.to(device=config.device)\n",
    "                optimizer.zero_grad()\n",
    "                Y_hat = model(X)\n",
    "                loss = torch.sqrt(loss_fn(Y_hat, Y))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                num_train_examples += len(Y)\n",
    "                tepoch.set_postfix(loss=loss.item(), examples=f'{round(num_train_examples/1000, 0)}K')\n",
    "\n",
    "                wandb.log({\"loss\": loss})\n",
    "                train_loss.append(loss.item())\n",
    "        \n",
    "        _, _, test_loss = test(model, config)\n",
    "        wandb.log({\"test_loss\": test_loss})\n",
    "\n",
    "    # calculate timesteps for the ODE trajectory\n",
    "    n_steps_per_epoch = math.ceil(len(train_loader.dataset) / config.batch_size)\n",
    "    epoch_time = [x/n_steps_per_epoch for x in range(len(train_loss))]\n",
    "\n",
    "    end = time.time()\n",
    "    wandb.log({\"total_train_examples\": num_train_examples})\n",
    "    print(f'training time: {end - start: .2f} sec')\n",
    "\n",
    "    return model, epoch_time, train_loss\n",
    "\n",
    "\n",
    "def test(model, config):\n",
    "    P = config.parameters\n",
    "    x0 = [1.5, 0.6, 0.7]\n",
    "\n",
    "    X = ode_utils.iterate(ode_utils.lorentz_ode, x0, n=3501, **P)\n",
    "    Y_dot = X[1:,:]\n",
    "    X = X[:-1,:]\n",
    "\n",
    "    X_torch = torch.tensor(X, dtype=torch.float32).to(config.device)\n",
    "    Y_hat = model(X_torch)\n",
    "    Y_hat = Y_hat.cpu().detach().numpy()\n",
    "\n",
    "    rmse_loss = np.sqrt(np.mean((Y_hat-Y_dot)**2))\n",
    "\n",
    "    wandb.log({\"test_loss\": rmse_loss})\n",
    "\n",
    "    return Y_dot, Y_hat, rmse_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config = SimpleNamespace(\n",
    "    # reproducability\n",
    "    seed=33,\n",
    "    \n",
    "    # train model\n",
    "    model_name=\"RecurrenceModel\",\n",
    "    hidden_units_list = [3,8,3],\n",
    "    activation_function = 'leaky_relu',\n",
    "    \n",
    "    # train regime\n",
    "    batch_size=32,  # 32 better than 64 better than 128\n",
    "    epochs=5,\n",
    "\n",
    "    # train data\n",
    "    dataset=\"np.random.normal([x:0,30, y:0,30, z:25,25], num_samples)\",\n",
    "    map_name=\"lorentz_ode\",\n",
    "    parameters = {'sigma': 10, 'beta': 8/3, 'rho': 28, 'dt': 0.01},\n",
    "    num_samples = 20**3,  # 30**3 better than 40**3\n",
    "    \n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.02305,  # hyper par tuning\n",
    "    weight_decay=0.006251,  # hyper par tuning\n",
    "    loss_fuc=\"RMSE\",\n",
    "\n",
    "    # device\n",
    "    device=\"mps\",\n",
    "    dtype=\"float32\",\n",
    "    # num_workers=4,\n",
    "    gpu_name=\"M1Pro GPU 16 Cores\",\n",
    ")\n",
    "\n",
    "run = wandb.init(project=\"iterate-lorentz-tm-v1.0\", config=config)\n",
    "\n",
    "device  = torch_utils.get_device()\n",
    "model, epoch_time, train_loss = train(config, device)\n",
    "\n",
    "Y_dot, Y_hat, test_loss = test(model, config)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 4))\n",
    "ax.plot(epoch_time, train_loss, label='loss')\n",
    "# ax.plot(epoch_time, train_accuracy, label='accuracy')\n",
    "ax.set_title(f'Train loss - final loss: ${train_loss[-1]: .5f}$')\n",
    "ax.set_xlabel('$epochs$')\n",
    "ax.set_ylabel('$loss$')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(16, 4))  #, gridspec_kw={'width_ratios': [3, 1]}, sharey=True)\n",
    "\n",
    "ax1.plot(Y_dot, marker='.', lw=1, label=['$\\dot{x}$', '$\\dot{y}$', '$\\dot{z}$'])\n",
    "ax1.plot(Y_hat, marker='.', lw=1, label=['$\\hat{x}$', '$\\hat{y}$', '$\\hat{z}$'])\n",
    "\n",
    "ax1.set_xlabel(f'$time$ $→$')\n",
    "ax1.set_ylabel(f'$x_t$, $y_t$, $z_t$')\n",
    "# ax1.legend(loc=\"upper left\")\n",
    "ax1.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_dot, y_dot, z_dot = tuple(Y_dot.T)\n",
    "x_hat, y_hat, z_hat = tuple(Y_hat.T)\n",
    "\n",
    "rmse_loss = np.sqrt(np.mean((Y_hat-Y_dot)**2))\n",
    "\n",
    "# plot the lorenz attractor in three-dimensional phase space\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(x_dot, y_dot, z_dot, color='b', alpha=0.7, linewidth=0.6, label='actual')\n",
    "ax.plot(x_hat, y_hat, z_hat, color='r', alpha=0.7, linewidth=0.6, label=f'predicted (rmse: {rmse_loss:.3f})')\n",
    "ax.set_title('Lorenz attractor phase diagram')\n",
    "ax.legend()\n",
    "\n",
    "# fig.savefig('{}/lorenz-attractor-3d.png'.format(save_folder), dpi=180, bbox_inches='tight')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In progress - reading model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(model)\n",
    "print(f'num_params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# for param in model.parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(param)\n",
    "\n",
    "# print('\\n')\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f'{name}: {param.cpu().detach().numpy().flatten()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "424ebd8b00407d2a464c0c6c29b98f8f4c2a6fb36382ca53d81afb3bb95714b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
